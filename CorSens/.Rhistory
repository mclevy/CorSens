Mu_zc[st[i]:end[i], ] <- apply(sigma_zy %*% solve(sigma_y) %*% (x[ ,i] - Mu_x[i]), MARGIN=2, FUN=function(x){x + matrix(Mu_x[-i])})
}
##  compute z_bp (bp = bar, prime); zt_p = xt_p[ ,-i]; z_bp = A_zc %*% z_tp + mu_zc; which follows (q = k-s)-dim conditional normal distribution in eq.(3.3)
Z_bp <- matrix(NA, nrow = q*k, ncol=N)
for (i in 1:k){
sigma_y <- sigma[i,i]
sigma_yz <- sigma[-i,i]
sigma_zy <- sigma[i,-i]
sigma_z <- sigma[-i,-i]
sigma_zc <- sigma_z - sigma_zy %*% solve(sigma_y) %*% sigma_yz
A_zc <- t(chol(sigma_zc))
Z_bp[st[i]:end[i], ] <- apply(xt_p[ ,-i], MARGIN=c(1), FUN=function(x){A_zc %*% x}) + Mu_zc[st[i]:end[i], ]
}
## create vector (y,z_bp)
nst <- seq(1,k*N,by=N) ; nend <- seq(N,k*N, by=N)
Y.Z_bp <- matrix(NA, nrow = k*N, ncol=k)
for (i in 1:k){
Y.Z_bp[nst[i]:nend[i],i] <- x[,i]
Y.Z_bp[nst[i]:nend[i],-i] <- t(Z_bp[st[i]:end[i], ])
}
## copula: transform normals to arbitrary marginal distribution
# Normal CDF
Y.Z_bp <- Fnorm(Y.Z_bp) # Uniforms
# Arbitrary quantile
Y.Z_bp <- Ginv(Y.Z_bp, distributions, params)
# Y.Z_bp: subsets of 1:N each, with rotating col i as the original col from x, z from Z_bp transform of z (-i) cols of xt_p
#########################################################################
### Construct (complimentary) set (y_bp, z)
## From above: xt_p = cbind(y_tp, z_tp) with rotating col=i as y_tp => y_tp = xt_p[ ,i]; the rest (-i) are z_tp
## compute mu_yc using z (from x[ ,-i]); mu_yc = mu_y + sigma_yz %*% solve(sigma_z) %*% (z-mu_z)
Mu_yc <- matrix(NA, nrow = 1*k, ncol=N)
for (i in 1:k){
sigma_yz <- sigma[-i,i]
sigma_z <- sigma[-i,-i]
Mu_yc[i, ] <- apply(sigma_yz %*% solve(sigma_z) %*% apply(x[ ,-i], MARGIN=1, FUN=function(x){x - Mu_x[-i]}), MARGIN=2, FUN=function(x){x + Mu_x[i]})
}
## compute y_bp (bp = bar, prime); y_bp = A_yc %*% y_tp + mu_yc; which follows 1-dim conditional normal distribution
Y_bp <- matrix(NA, nrow = 1*k, ncol=N)
for (i in 1:k){
# partitioned sigma matrix: same for all subsets of x
sigma_y <- sigma[i,i]
sigma_yz <- sigma[-i,i]
sigma_zy <- sigma[i,-i]
sigma_z <- sigma[-i,-i]
sigma_yc <- sigma_y - sigma_yz %*% solve(sigma_z) %*% sigma_zy
A_yc <- t(chol(sigma_yc)) # A_yc %*% t(A_yc)
Y_bp[i, ] <- apply(matrix(xt_p[ ,i]), MARGIN=c(1), FUN=function(x){A_yc %*% x} ) + Mu_yc[i, ]
}
##  create vector cbind(y_bp,z)
Y_bp.Z <- matrix(NA, nrow = k*N, ncol=k)
for (i in 1:k){
Y_bp.Z[nst[i]:nend[i],i] <- Y_bp[i, ]
Y_bp.Z[nst[i]:nend[i],-i] <-  x[,-i]
}
## copula: transform normals to arbitrary marginal distribution
# Normal CDF
Y_bp.Z <- Fnorm(Y_bp.Z) # Uniforms
# Arbitrary quantile
Y_bp.Z <- Ginv(Y_bp.Z, distributions, params)
# Y_bp.Z: subsets of 1:N each, with rotating col i as the Y_bp col from transformed xt_p (i) cols; z from original x (-i)
#########################################################################
### Construct joint set (y, z)
# Joint set (y,z) is just the original x matrix x=(y,z); the "y" will be the rotating col i, and the z the (-i) cols for i = 1,...,k
## copula: transform normals to arbitrary marginal distribution
# Normal CDF
Y.Z <- Fnorm(x) # Uniforms
# Arbitrary quantile
Y.Z <- Ginv(Y.Z, distributions, params)
#########################################################################
### Calculate Sensitivity Indices SY and STy
mod <- model
fboot <- function(X) sample(X, size=N, replace=TRUE)
Y.Z_boot <- apply(Y.Z,2,fboot)
Y.Z_bp_boot <- apply(Y.Z_bp,2,fboot)
Y_bp.Z_boot <- apply(Y_bp.Z,2,fboot)
f.yz <- matrix(mod(Y.Z_boot)) # ouput matrix (N x 1)
f.y.z_bp <- matrix(mod(Y.Z_bp_boot), ncol=k) # output matrix (N x k) for each k subset
f.y_bp.z <- matrix(mod(Y_bp.Z_boot), ncol=k) # output matrix (N x k) for each k subset
f0 <- sum(f.yz, na.rm = TRUE)/N
D <- sum(f.yz^2, na.rm = TRUE)/N - f0^2
Sy <- apply(f.y.z_bp, MARGIN=2, FUN=function(x){(sum(f.yz * x, na.rm = TRUE)/N - f0^2)/D})
STy <- apply(f.y_bp.z, MARGIN=2, FUN=function(x){(sum((f.yz - x)^2, na.rm = TRUE)/N)/(2*D)})
# results table with thresholds
kk <- list(Sy, STy)
names(kk)=c("SY", "STy")
thresh <- threshold
threshnames_i <- paste(thresh, "_i", sep="")
threshnames_T <- paste(thresh, "_T", sep="")
results_names <- c("Rank_i", threshnames_i, "Rank_T", threshnames_T)
vi <- seq(1:k)
oi <- order(kk$SY, decreasing = T)
ot <- order(kk$STy, decreasing = T)
if (test == T){
nms <- as.character(1:k)
} else {
nms <- names(data)
}
results <- matrix(0, nrow = k, ncol=length(results_names), dimnames = list(nms, results_names))
results <- as.data.frame(results)
for (i in 1:k){
results[oi[i],"Rank_i"] <- vi[i]
results[ot[i],"Rank_T"] <- vi[i]
}
for (i in 1:length(thresh)){
if (sum(kk$SY > threshnames_i[i]) > 0){
results[kk$SY > threshnames_i[i], threshnames_i[i]] <- "X"
}
if (sum(kk$STy > threshnames_T[i]) > 0){
results[kk$STy > threshnames_T[i], threshnames_T[i]] <- "X"
}
}
results[results == 0] <- "."
out=list(Sy, STy, results)
names(out)=c("SY", "STy", "results")
return(out)
}
N <- 10^4
k <- 3
# data
u <- matrix(runif(N*k, min=-pi, max = pi), nrow=N)
mu_x <- colMeans(u)
# correlation
corseq <- seq(-0.9, 0.9,length.out=10)
#toy model
ishigami <- function(data){
Y <- ( sin(data[ ,1]) + (7*(sin(data[ ,2]))^2)
+ (0.1* ((data[ ,3])^4) * sin(data[ ,1])) )
return(Y)
}
# initialize
ki_mat <- matrix(NA, nrow = k, ncol=length(corseq),
dimnames = list(1:k, corseq)) # indiv index matrix
kt_mat <- matrix(NA, nrow = k, ncol=length(corseq),
dimnames = list(1:k, corseq)) # total index matrix
for (i in 1:length(corseq)){
# Desired correlation (of input data variables) = actual cor
rho <- 0.0
sigma <- matrix(rep(NA, k^2), nrow=k) # cor mat init
std <- 1
diag(sigma) <- std^2 ; sigma[lower.tri(sigma)] <- rho ;
sigma[upper.tri(sigma)] <- rho
sigma[1,3] <- sigma[3,1] <- corseq[i]
ki <- suppressWarnings(K12(data = u, N=N, model=ishigami, sigma = sigma))
# suppress warnings because sigma has all(diag(sigma) == 1), which triggers warning message about checking that cov matrix supplied (instead of cor)
ki_mat[ ,i] <- ki$SY
kt_mat[ ,i] <- ki$STy
print(i)
}
plot(corseq, ki_mat[1, ], ylab="Sensitivity Index Value", type="b",
pch=21, lty=1, ylim=c(0,0.7), col=1, xlab=expression(rho["1,3"]))
lines(corseq, kt_mat[1, ], ylab="Index Value", type="b",
pch=21, lty=2, col=1)
lines(corseq, ki_mat[2, ], ylab="Index Value", type="b",
pch=24, lty=1, col=2)
lines(corseq, kt_mat[2, ], ylab="Index Value", type="b",
pch=24, lty=2, col=2)
lines(corseq, ki_mat[3, ], ylab="Index Value", type="b",
pch=23, lty=1, col=4)
lines(corseq, kt_mat[3, ], ylab="Index Value", type="b",
pch=23, lty=2, col=4)
kt_mat
ki_mat
k <- 3
# data
u <- matrix(runif(N*k, min=-pi, max = pi), nrow=N)
mu_x <- colMeans(u)
# correlation
corseq <- seq(-0.9, 0.9,length.out=10)
#toy model
ishigami <- function(data){
Y <- ( sin(data[ ,1]) + (7*(sin(data[ ,2]))^2)
+ (0.1* ((data[ ,3])^4) * sin(data[ ,1])) )
return(Y)
}
i=1
rho <- 0.0
sigma <- matrix(rep(NA, k^2), nrow=k) # cor mat init
std <- 1
diag(sigma) <- std^2 ; sigma[lower.tri(sigma)] <- rho ;
sigma[upper.tri(sigma)] <- rho
sigma[1,3] <- sigma[3,1] <- corseq[i]
data = u
N=N
model=ishigami
sigma = sigma
distributions=NULL
parameters = NULL
k=NULL
mu = NULL
if(is.null(data) && is.null(sigma)) stop("If no data is provided, must specify sigma matrix")
if(is.null(data) == T && is.null(parameters)) stop("If no data is provided, must specify parameters for chosen (default uniform) distributions")
if(is.null(data) == T && is.null(mu)) stop("If no data is provided, must specify mean (vector) for distributions")
if(is.null(data) == T && is.null(k)) stop("If no data is provided, must specify k = the number of data variables")
if(is.null(model)) stop("Model function is missing")
if (is.null(k) == T){
k <- dim(data)[2]
test <- F
} else {
k <- k
test <- T
}
q <- k-1
## specify distributions according to inputs (data or mu,sigma,k specified for a simulated distribution)
if (is.null(distributions) && (is.null(data) == F)){
distributions <- rep("unif", ncol(data))
} else if (is.null(distributions) && (is.null(data) == T)){
distributions <- rep("unif", k)
} else {
distributions <- distributions
}
if (is.null(data) == T){  # no data matrix
if(k != length(distributions)) stop("Number of variables (k) does not match the length of the list of distributions")
if(k != length(mu)) stop("Number of variables (k) does not match the length of the mean vector")
if(k != length(diag(sigma)) ) stop("Number of variables (k) does not match the rows and columns of sigma")
if(k != length(parameters) ) stop("Number of variables (k) does not match the length of the list of distribution parameters")
} else if (is.null(data) == F){
if(ncol(data) != length(distributions)) stop("Number of variables (data columns) does not match the length of the list of distributions")
}
##  extract arbitrary distribution parameters for use in later transformations
if (is.null(parameters) == T){
params <- ParamFit(data, distributions)
} else {
params <- parameters
}
## Specify transformed sigma; from data and distributions, or entered manually
if (is.null(sigma) == F){
sigma <- sigma
} else if (is.null(sigma)){
sigma <- cov(data,use="pairwise.complete.obs")
}
if(all(rep(1,k) == diag(sigma))) warning("Check that sigma is a covariance (not correlation) matrix; covariance matrix must be supplied")
if (is.null(sigma) == T){
sigma <- CorTransform(data, k=k, distributions)
} else if (is.null(data) == F && is.null(sigma) == F){
sigma <- CorTransform(data=data, k=k, distributions, sigma)
} else if (all(diag(k) == sigma) == F && is.null(data) == T && is.null(sigma) == F && is.null(mu) == F){
sigma <- CorTransform(distributions=distributions,k=k, sigma=sigma, mu=mu)
} # all(diag(k) == sigma): leave sigma as is if == I
if(is.positive.semi.definite(round(sigma,2)) == F) stop("Correlation matrix is not positive semi-definite.")
#########################################################################
### Set up for: Construct sets (y,z), (y, z_bp) and complimentary set (y_bp, z)
## x = (y,z), x_p = (y_tp, z_tp) ; t=tilde, p=prime (paper notation)
## x= (y, z) with rotating col=i as y; the rest (-i) are z.
# x matrix contains CORRELATED variables; gen normals and transform using sigma
u <- matrix(runif((k) * N), nrow = N) # k-2-dim (k-2 = correlated vars only) ; uniform sample, u
xt <- qnorm(u) # normal inverse transform
if (is.null(mu) == T){
mu_x <- c(colMeans(data, na.rm=T))
}else{
mu_x <- mu
}
# print(sigma)
A <- t(chol(sigma)) # check: A %*% t(A) = sigma ; sigma is just correlated vars
x <- t( apply(A %*% t(xt), MARGIN=2, FUN=function(x){x + mu_x}))
# pairs(x[sample(nrow(x),10^3), ])
## x_p = cbind(y_tp, z_tp) with rotating col=i as y_tp; the rest (-i) cols are z_tp
# x_tp matrix is UNCORRELATED standard normal variables = no transformation using sigma
u_p <- matrix(runif(k * N), nrow = N) # k-dim uniform sample, u_p
xt_p <- qnorm(u_p) # transform to standard normal
# pairs(xt_p[sample(nrow(x),10^3), ])
## Calculate mu's = mu_y, mu_z: For matrix x, mu_y is colMeans of the y "subset" col (i) for each subset; mu_z is the colMeans of the remaining (-i) cols of x.
Mu_x <- colMeans(x)
# Mu_xt_p <- colMeans(xt_p) # not used below
#########################################################################
### Construct set (y, z_bp)
## compute mu_zc using y; from eqn.(3.4): mu_zc = mu_z + sigma_zy %*% solve(sigma_y) %*% (y-mu_y)
st <- seq(1,q*k,by=q) ; end <- seq(q,k*q, by=q) # index
Mu_zc <- matrix(NA, nrow = q*k, ncol=N)
# computes Mu_zc for each subset i = 1:3, for each N samples
for (i in 1:k){
# partitioned sigma matrix: same for all subsets of x
sigma_y <- matrix(sigma[i,i])
sigma_zy <- matrix(sigma[i,-i])
Mu_zc[st[i]:end[i], ] <- apply(sigma_zy %*% solve(sigma_y) %*% (x[ ,i] - Mu_x[i]), MARGIN=2, FUN=function(x){x + matrix(Mu_x[-i])})
}
##  compute z_bp (bp = bar, prime); zt_p = xt_p[ ,-i]; z_bp = A_zc %*% z_tp + mu_zc; which follows (q = k-s)-dim conditional normal distribution in eq.(3.3)
Z_bp <- matrix(NA, nrow = q*k, ncol=N)
for (i in 1:k){
sigma_y <- sigma[i,i]
sigma_yz <- sigma[-i,i]
sigma_zy <- sigma[i,-i]
sigma_z <- sigma[-i,-i]
sigma_zc <- sigma_z - sigma_zy %*% solve(sigma_y) %*% sigma_yz
A_zc <- t(chol(sigma_zc))
Z_bp[st[i]:end[i], ] <- apply(xt_p[ ,-i], MARGIN=c(1), FUN=function(x){A_zc %*% x}) + Mu_zc[st[i]:end[i], ]
}
## create vector (y,z_bp)
nst <- seq(1,k*N,by=N) ; nend <- seq(N,k*N, by=N)
Y.Z_bp <- matrix(NA, nrow = k*N, ncol=k)
for (i in 1:k){
Y.Z_bp[nst[i]:nend[i],i] <- x[,i]
Y.Z_bp[nst[i]:nend[i],-i] <- t(Z_bp[st[i]:end[i], ])
}
## copula: transform normals to arbitrary marginal distribution
# Normal CDF
Y.Z_bp <- Fnorm(Y.Z_bp) # Uniforms
# Arbitrary quantile
Y.Z_bp <- Ginv(Y.Z_bp, distributions, params)
# Y.Z_bp: subsets of 1:N each, with rotating col i as the original col from x, z from Z_bp transform of z (-i) cols of xt_p
#########################################################################
### Construct (complimentary) set (y_bp, z)
## From above: xt_p = cbind(y_tp, z_tp) with rotating col=i as y_tp => y_tp = xt_p[ ,i]; the rest (-i) are z_tp
## compute mu_yc using z (from x[ ,-i]); mu_yc = mu_y + sigma_yz %*% solve(sigma_z) %*% (z-mu_z)
Mu_yc <- matrix(NA, nrow = 1*k, ncol=N)
for (i in 1:k){
sigma_yz <- sigma[-i,i]
sigma_z <- sigma[-i,-i]
Mu_yc[i, ] <- apply(sigma_yz %*% solve(sigma_z) %*% apply(x[ ,-i], MARGIN=1, FUN=function(x){x - Mu_x[-i]}), MARGIN=2, FUN=function(x){x + Mu_x[i]})
}
## compute y_bp (bp = bar, prime); y_bp = A_yc %*% y_tp + mu_yc; which follows 1-dim conditional normal distribution
Y_bp <- matrix(NA, nrow = 1*k, ncol=N)
for (i in 1:k){
# partitioned sigma matrix: same for all subsets of x
sigma_y <- sigma[i,i]
sigma_yz <- sigma[-i,i]
sigma_zy <- sigma[i,-i]
sigma_z <- sigma[-i,-i]
sigma_yc <- sigma_y - sigma_yz %*% solve(sigma_z) %*% sigma_zy
A_yc <- t(chol(sigma_yc)) # A_yc %*% t(A_yc)
Y_bp[i, ] <- apply(matrix(xt_p[ ,i]), MARGIN=c(1), FUN=function(x){A_yc %*% x} ) + Mu_yc[i, ]
}
##  create vector cbind(y_bp,z)
Y_bp.Z <- matrix(NA, nrow = k*N, ncol=k)
for (i in 1:k){
Y_bp.Z[nst[i]:nend[i],i] <- Y_bp[i, ]
Y_bp.Z[nst[i]:nend[i],-i] <-  x[,-i]
}
## copula: transform normals to arbitrary marginal distribution
# Normal CDF
Y_bp.Z <- Fnorm(Y_bp.Z) # Uniforms
# Arbitrary quantile
Y_bp.Z <- Ginv(Y_bp.Z, distributions, params)
# Y_bp.Z: subsets of 1:N each, with rotating col i as the Y_bp col from transformed xt_p (i) cols; z from original x (-i)
#########################################################################
### Construct joint set (y, z)
# Joint set (y,z) is just the original x matrix x=(y,z); the "y" will be the rotating col i, and the z the (-i) cols for i = 1,...,k
## copula: transform normals to arbitrary marginal distribution
# Normal CDF
Y.Z <- Fnorm(x) # Uniforms
# Arbitrary quantile
Y.Z <- Ginv(Y.Z, distributions, params)
mod <- model
hist(Y.Z[ ,1]) ; hist(Y.Z[ ,2]); hist(Y.Z[ ,3])
hist(Y.Z_bp[ ,1]) ; hist(Y.Z_bp[ ,2]); hist(Y.Z_bp[ ,3])
hist(Y_bp.Z[ ,1]) ; hist(Y_bp.Z[ ,2]); hist(Y_bp.Z[ ,3])
round(cor(Y.Z),1)
round(cor(Y.Z_bp),1)
round(cor(Y_bp.Z),1)
fboot <- function(X) sample(X, size=N, replace=TRUE)
Y.Z_boot <- apply(Y.Z,2,fboot)
Y.Z_bp_boot <- apply(Y.Z_bp,2,fboot)
Y_bp.Z_boot <- apply(Y_bp.Z,2,fboot)
hist(Y.Z_boot[ ,1]) ; hist(Y.Z_boot[ ,2]); hist(Y.Z_boot[ ,3])
hist(Y.Z_bp_boot[ ,1]) ; hist(Y.Z_bp_boot[ ,2]); hist(Y.Z_bp_boot[ ,3])
hist(Y_bp.Z_boot[ ,1]) ; hist(Y_bp.Z_boot[ ,2]); hist(Y_bp.Z_boot[ ,3])
round(cor(Y.Z_boot),1)
round(cor(Y.Z_bp_boot),1)
round(cor(Y_bp.Z_boot),1)
332*.1
?lme
??lme
?glm
library(lme4)
setwd("C:/Documents and Settings/XPMUser/Desktop/Hierarchical Modeling Spring 2013")
getwd()
library(lme4)
install.packages("lme4")
?factor
?glm
?lme4
lme4
lme
?lme
library(nlme)
?lme
fm1 <- lme(distance ~ age, data = Orthodont)
summary(fm1)
names(fm1)
summary(z)
plot(z)
fm2 <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1)
plot(fm1)
intervals(fm1)
resid(fm1)
fitted(fm1)
VarCorr(fm1)
anova(fm1)
anova(fm1, fm2)
>lmer
?lmer
library(lme4)
?lmer
(fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
fm1 <- lmer(distance ~ age, data = Orthodont)
(fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
summary(fm1)
(fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy))
anova(fm1, fm2)
print(fm2, digits=7, ranef.comp="Var")
print(fm2, digits=7, ranef.comp="Var") # the print.merMod()         method
print(sm2, digits=3, corr=FALSE)
sm2 <- summary(fm2)
print(sm2, digits=3, corr=FALSE)
vv <- vcov.merMod(fm2, corr=TRUE)
vv
as(vv, "corMatrix")
model_lmer<-lmer(distance~age+Sex+(1|Subject),data=Orthodont)
model_lme<-lme(distance~age+Sex, random=~1|Subject,data=Orthodont)
summary(model_lmer)
anova(model_lmer)
summary(model_lme)
summary(model_lme)
anova(model_lme)
plot(ranef(model_lme)) # lme
qqmath(ranef(model_lmer))
res_lme=residuals(model_lme)
plot(res_lme)
qqnorm(res_lme)
qqline(res_lme)
plot(model_lme)
res_lme=residuals(model_lmer)
plot(res_lme)
plot(res_lmer)
res_lmer=residuals(model_lmer)
plot(res_lmer)
qqnorm(res_lmer)
qqline(res_lmer)
plot(model_lmer)
plot(model_lmer)
model_lme<-lme(distance ~ age + factor(Sex),random = ~ 1 | Subject, cor=corAR1(0.6,form=~1|Subject),data = Orthodont)
VarCorr(model_lme)
library(lmerTest)
install.packages("lmerTest")
?lmerTest
m <- lmer(Informed.liking ~ Gender+Information+Product +(1|Consumer), data=ham)
library(lmerTest)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
summary(fm1)# (with its own print method)
anova(fm1)
?lmer
library(lmerTest)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
anova(fm1)
?K12
library(CorSens)
?K12
rm(list= ls());
master <- "/Users/mcl/Dropbox/Year3/STATS_MA/code/final/CorSens_package/CorSens"
setwd(master)
# load libraries
library(devtools)
library(roxygen2)
library(devtools)
library(roxygen2)
load_all(master, T)
document(".")
check_doc()
test()
check()
load_all(master, T)
# update documentation
document(".")
check_doc()
load_all(master, T)
# update documentation
document(".")
check_doc()
test()
check()
build_vignettes()
build()
install("/Users/mcl/Dropbox/Year3/STATS_MA/code/final/CorSens_package/CorSens")
library(CorSens)
?CorSens
vignette(package = "CorSens")
vignette("tests", package = "CorSens")
vignette("example", package = "CorSens")
vignette("example", package = "CorSens")
rm(list= ls());
master <- "/Users/mcl/Dropbox/Year3/STATS_MA/code/final/CorSens_package/CorSens"
setwd(master)
# load libraries
library(devtools)
library(roxygen2)
load_all(master, T)
document(".")
check_doc()
test()
check()
build_vignettes()
build_vignettes()
build()
install("/Users/mcl/Dropbox/Year3/STATS_MA/code/final/CorSens_package/CorSens")
library(CorSens)
?CorSens
vignette(package = "CorSens") # see names
vignette("tests", package = "CorSens")
vignette("example", package = "CorSens")
library(sensitivity)
?sobol2002
vignette(package = "sensitivity")
X1<-data.frame(a=runif(100,20,30),b=runif(100,0.1,0.5))
X2<-data.frame(a=runif(100,20,30),b=runif(100,0.1,0.5))
hist(X1)
X2
hist(X1[ ,1])
hist(X1[ ,2])
sobol.fun(X)
sobol.fun
?K12
